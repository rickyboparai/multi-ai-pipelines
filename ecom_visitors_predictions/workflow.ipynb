{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "503d2dc6-0ff4-4adb-a88b-c31311ddcd76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_unixtime\n",
    "\n",
    "df_events = spark.table(\"e2e.default.events\")\n",
    "\n",
    "events_columns = df_events.select(\n",
    "    \"timestamp\", \"visitorid\", \"event\", \"transactionid\", \"itemid\"\n",
    ")\n",
    "final_df_events = events_columns.withColumn(\n",
    "    \"event_datetime\", from_unixtime(col(\"timestamp\")/1000)\n",
    ")\n",
    "\n",
    "df_items = spark.table(\"e2e.default.item_properties_part1\")\n",
    "df_items_clean = df_items.where(\"property in ('available', 'categoryid')\")\n",
    "items_columns = df_items_clean.select(\"timestamp\", \"itemid\", \"property\", \"value\")\n",
    "final_df_items = items_columns.withColumn(\n",
    "    \"item_datetime\", from_unixtime(col(\"timestamp\")/1000)\n",
    ")\n",
    "\n",
    "joined_df = final_df_events.join(\n",
    "    final_df_items,\n",
    "    final_df_events[\"itemid\"] == final_df_items[\"itemid\"],\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "joined_df = joined_df.select(\n",
    "    \"visitorid\",\n",
    "    \"event\",\n",
    "    \"transactionid\",\n",
    "    \"event_datetime\",\n",
    "    final_df_items[\"itemid\"],\n",
    "    \"property\",\n",
    "    \"value\",\n",
    "    \"item_datetime\"\n",
    ")\n",
    "\n",
    "joined_df = joined_df.dropDuplicates()\n",
    "joined_df.write.format(\"delta\").saveAsTable(\"e2e.default.events_items_silver\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68aee41b-5573-4106-9747-3c3a413c04a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "WITH visitor_stats AS (\n",
    "    SELECT\n",
    "        visitorid,\n",
    "        COUNT(*) AS visitor_total_events,\n",
    "        SUM(CASE WHEN event = 'transaction' THEN 1 END) AS visitor_purchase_count,\n",
    "        ROUND(SUM(CASE WHEN event = 'transaction' THEN 1 END) * 100.0 / COUNT(*), 2) AS visitor_conversion_rate,\n",
    "        MAX(CASE WHEN event = 'transaction' THEN event_datetime END) AS last_purchase_time,\n",
    "        ROUND((UNIX_TIMESTAMP(MAX(event_datetime)) - UNIX_TIMESTAMP(MIN(event_datetime))) / 60, 2) AS session_length\n",
    "    FROM events_items_silver\n",
    "    GROUP BY visitorid\n",
    "),\n",
    "base_features AS (\n",
    "    SELECT\n",
    "        e.transactionid,\n",
    "        e.visitorid,\n",
    "        vs.visitor_total_events,\n",
    "        vs.visitor_purchase_count,\n",
    "        vs.visitor_conversion_rate,\n",
    "        vs.last_purchase_time,\n",
    "        DATEDIFF(vs.last_purchase_time, MAX(e.event_datetime)) AS visitor_days_since_last_purchase,\n",
    "        vs.session_length,\n",
    "        COUNT(DISTINCT e.itemid) AS unique_items_basket_size\n",
    "    FROM events_items_silver e\n",
    "    JOIN visitor_stats vs ON e.visitorid = vs.visitorid\n",
    "    WHERE e.transactionid IS NOT NULL\n",
    "    GROUP BY\n",
    "        e.transactionid,\n",
    "        e.visitorid,\n",
    "        vs.visitor_total_events,\n",
    "        vs.visitor_purchase_count,\n",
    "        vs.visitor_conversion_rate,\n",
    "        vs.last_purchase_time,\n",
    "        vs.session_length\n",
    "),\n",
    "view_labels AS (\n",
    "    SELECT\n",
    "        v.visitorid,\n",
    "        v.transactionid,\n",
    "        v.itemid,\n",
    "        v.event_datetime AS view_time,\n",
    "        CASE WHEN COUNT(p.event_datetime) > 0 THEN 1 ELSE 0 END AS visitor_item_purchase_label\n",
    "    FROM events_items_silver v\n",
    "    LEFT JOIN events_items_silver p\n",
    "        ON v.visitorid = p.visitorid\n",
    "       AND v.itemid = p.itemid\n",
    "       AND p.event = 'view'\n",
    "       AND p.event_datetime > v.event_datetime\n",
    "       AND p.event_datetime <= v.event_datetime + INTERVAL 60 DAY\n",
    "    WHERE v.event = 'transaction'\n",
    "    GROUP BY v.visitorid, v.transactionid, v.itemid, v.event_datetime\n",
    ")\n",
    "SELECT\n",
    "    DISTINCT\n",
    "    bf.*,\n",
    "    vl.visitor_item_purchase_label\n",
    "FROM base_features as bf\n",
    "JOIN view_labels vl\n",
    "    ON vl.visitorid = bf.visitorid\n",
    "   AND vl.transactionid = bf.transactionid ORDER BY bf.transactionid\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"e2e.default.visitor_transactions_gold\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "workflow",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
